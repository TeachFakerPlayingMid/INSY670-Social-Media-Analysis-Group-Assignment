{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Find predictors of influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "from joblib import dump\n",
    "\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path() / \"../data\"\n",
    "DATA_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "def load_data(filename, data_path=DATA_PATH,encoding='ISO-8859-1'):\n",
    "    csv_path = data_path / filename\n",
    "    return pd.read_csv(csv_path,encoding=encoding)\n",
    "\n",
    "def save_data(data, filename, data_path=DATA_PATH,encoding='ISO-8859-1'):\n",
    "    csv_path = data_path / filename\n",
    "    data.to_csv(csv_path, index=False,encoding='ISO-8859-1')\n",
    "\n",
    "PLOT_PATH = Path() / \"../plot\"\n",
    "PLOT_PATH.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300, transparent=True):\n",
    "    path = PLOT_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, transparent=transparent)\n",
    "\n",
    "# Define a path for saving models\n",
    "MODEL_PATH = Path() / \"../models\"\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "def save_model(model, filename, model_path=MODEL_PATH):\n",
    "    model_save_path = model_path / filename\n",
    "    dump(model,model_save_path)\n",
    "\n",
    "def load_model(filename, model_path=MODEL_PATH):\n",
    "    model_load_path = model_path / filename\n",
    "    return load(model_load_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missingno import matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Choice</th>\n",
       "      <th>A_follower_count</th>\n",
       "      <th>A_following_count</th>\n",
       "      <th>A_listed_count</th>\n",
       "      <th>A_mentions_received</th>\n",
       "      <th>A_retweets_received</th>\n",
       "      <th>A_mentions_sent</th>\n",
       "      <th>A_retweets_sent</th>\n",
       "      <th>A_posts</th>\n",
       "      <th>A_network_feature_1</th>\n",
       "      <th>...</th>\n",
       "      <th>B_following_count</th>\n",
       "      <th>B_listed_count</th>\n",
       "      <th>B_mentions_received</th>\n",
       "      <th>B_retweets_received</th>\n",
       "      <th>B_mentions_sent</th>\n",
       "      <th>B_retweets_sent</th>\n",
       "      <th>B_posts</th>\n",
       "      <th>B_network_feature_1</th>\n",
       "      <th>B_network_feature_2</th>\n",
       "      <th>B_network_feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>0.583979</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.362150</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>29808</td>\n",
       "      <td>1689</td>\n",
       "      <td>15.430498</td>\n",
       "      <td>3.984029</td>\n",
       "      <td>8.204331</td>\n",
       "      <td>0.332423</td>\n",
       "      <td>6.988815</td>\n",
       "      <td>66</td>\n",
       "      <td>75.530303</td>\n",
       "      <td>1916.893939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21591</td>\n",
       "      <td>1179</td>\n",
       "      <td>228</td>\n",
       "      <td>90.456506</td>\n",
       "      <td>25.798292</td>\n",
       "      <td>5.709329</td>\n",
       "      <td>1.111159</td>\n",
       "      <td>5.176620</td>\n",
       "      <td>369</td>\n",
       "      <td>...</td>\n",
       "      <td>848</td>\n",
       "      <td>1610</td>\n",
       "      <td>40.495021</td>\n",
       "      <td>8.943607</td>\n",
       "      <td>3.227677</td>\n",
       "      <td>0.564343</td>\n",
       "      <td>1.070321</td>\n",
       "      <td>163</td>\n",
       "      <td>132.030675</td>\n",
       "      <td>2931.515337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7310</td>\n",
       "      <td>1215</td>\n",
       "      <td>101</td>\n",
       "      <td>25.503644</td>\n",
       "      <td>9.556347</td>\n",
       "      <td>5.361519</td>\n",
       "      <td>0.591206</td>\n",
       "      <td>3.589718</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>482</td>\n",
       "      <td>206</td>\n",
       "      <td>0.734696</td>\n",
       "      <td>0.354379</td>\n",
       "      <td>0.603202</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.603202</td>\n",
       "      <td>3</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>277.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7.690824</td>\n",
       "      <td>0.277306</td>\n",
       "      <td>1.331508</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>2.830627</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>17637</td>\n",
       "      <td>278</td>\n",
       "      <td>572.874856</td>\n",
       "      <td>390.293681</td>\n",
       "      <td>27.552040</td>\n",
       "      <td>7.167557</td>\n",
       "      <td>32.101906</td>\n",
       "      <td>1762</td>\n",
       "      <td>23.469296</td>\n",
       "      <td>1395.845634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>45589</td>\n",
       "      <td>862</td>\n",
       "      <td>2641</td>\n",
       "      <td>148.854279</td>\n",
       "      <td>36.998884</td>\n",
       "      <td>27.881768</td>\n",
       "      <td>3.333492</td>\n",
       "      <td>23.861282</td>\n",
       "      <td>551</td>\n",
       "      <td>...</td>\n",
       "      <td>1711</td>\n",
       "      <td>181</td>\n",
       "      <td>21.601866</td>\n",
       "      <td>3.581661</td>\n",
       "      <td>6.764657</td>\n",
       "      <td>1.119727</td>\n",
       "      <td>4.563246</td>\n",
       "      <td>85</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>1993.627907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Choice  A_follower_count  A_following_count  A_listed_count  \\\n",
       "0       0               228                302               3   \n",
       "1       0             21591               1179             228   \n",
       "2       0              7310               1215             101   \n",
       "3       0                20                  7               2   \n",
       "4       1             45589                862            2641   \n",
       "\n",
       "   A_mentions_received  A_retweets_received  A_mentions_sent  A_retweets_sent  \\\n",
       "0             0.583979             0.100503         0.100503         0.100503   \n",
       "1            90.456506            25.798292         5.709329         1.111159   \n",
       "2            25.503644             9.556347         5.361519         0.591206   \n",
       "3             7.690824             0.277306         1.331508         0.100503   \n",
       "4           148.854279            36.998884        27.881768         3.333492   \n",
       "\n",
       "     A_posts  A_network_feature_1  ...  B_following_count  B_listed_count  \\\n",
       "0   0.362150                    2  ...              29808            1689   \n",
       "1   5.176620                  369  ...                848            1610   \n",
       "2   3.589718                   95  ...                482             206   \n",
       "3   2.830627                    6  ...              17637             278   \n",
       "4  23.861282                  551  ...               1711             181   \n",
       "\n",
       "   B_mentions_received  B_retweets_received  B_mentions_sent  B_retweets_sent  \\\n",
       "0            15.430498             3.984029         8.204331         0.332423   \n",
       "1            40.495021             8.943607         3.227677         0.564343   \n",
       "2             0.734696             0.354379         0.603202         0.100503   \n",
       "3           572.874856           390.293681        27.552040         7.167557   \n",
       "4            21.601866             3.581661         6.764657         1.119727   \n",
       "\n",
       "     B_posts  B_network_feature_1  B_network_feature_2  B_network_feature_3  \n",
       "0   6.988815                   66            75.530303          1916.893939  \n",
       "1   1.070321                  163           132.030675          2931.515337  \n",
       "2   0.603202                    3            10.333333           277.333333  \n",
       "3  32.101906                 1762            23.469296          1395.845634  \n",
       "4   4.563246                   85            48.500000          1993.627907  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = load_data(\"train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Choice</th>\n",
       "      <th>A_follower_count</th>\n",
       "      <th>A_following_count</th>\n",
       "      <th>A_listed_count</th>\n",
       "      <th>A_mentions_received</th>\n",
       "      <th>A_retweets_received</th>\n",
       "      <th>A_mentions_sent</th>\n",
       "      <th>A_retweets_sent</th>\n",
       "      <th>A_posts</th>\n",
       "      <th>A_network_feature_1</th>\n",
       "      <th>...</th>\n",
       "      <th>B_following_count</th>\n",
       "      <th>B_listed_count</th>\n",
       "      <th>B_mentions_received</th>\n",
       "      <th>B_retweets_received</th>\n",
       "      <th>B_mentions_sent</th>\n",
       "      <th>B_retweets_sent</th>\n",
       "      <th>B_posts</th>\n",
       "      <th>B_network_feature_1</th>\n",
       "      <th>B_network_feature_2</th>\n",
       "      <th>B_network_feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5.500000e+03</td>\n",
       "      <td>5.500000e+03</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5.500000e+03</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5.500000e+03</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.509455</td>\n",
       "      <td>6.498840e+05</td>\n",
       "      <td>1.265895e+04</td>\n",
       "      <td>5952.453273</td>\n",
       "      <td>2.666032e+03</td>\n",
       "      <td>1032.371839</td>\n",
       "      <td>6.011873</td>\n",
       "      <td>1.109924</td>\n",
       "      <td>9.090730</td>\n",
       "      <td>5267.768000</td>\n",
       "      <td>...</td>\n",
       "      <td>12738.259818</td>\n",
       "      <td>5903.148364</td>\n",
       "      <td>2.554598e+03</td>\n",
       "      <td>997.149954</td>\n",
       "      <td>6.099658</td>\n",
       "      <td>1.106236</td>\n",
       "      <td>9.505821</td>\n",
       "      <td>5254.933636</td>\n",
       "      <td>85.024196</td>\n",
       "      <td>3745.175480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499956</td>\n",
       "      <td>2.028787e+06</td>\n",
       "      <td>4.900867e+04</td>\n",
       "      <td>17339.141191</td>\n",
       "      <td>2.916543e+04</td>\n",
       "      <td>10954.953223</td>\n",
       "      <td>9.519797</td>\n",
       "      <td>1.910104</td>\n",
       "      <td>18.311060</td>\n",
       "      <td>28946.777345</td>\n",
       "      <td>...</td>\n",
       "      <td>50054.520874</td>\n",
       "      <td>16298.462018</td>\n",
       "      <td>2.508873e+04</td>\n",
       "      <td>9342.006880</td>\n",
       "      <td>9.729557</td>\n",
       "      <td>1.939914</td>\n",
       "      <td>19.424680</td>\n",
       "      <td>26778.820125</td>\n",
       "      <td>106.689384</td>\n",
       "      <td>5518.399590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005034e-01</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005034e-01</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.663750e+03</td>\n",
       "      <td>3.220000e+02</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>3.453649e+00</td>\n",
       "      <td>0.716816</td>\n",
       "      <td>0.359534</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.632440</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>3.260473e+00</td>\n",
       "      <td>0.714556</td>\n",
       "      <td>0.356943</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.822584</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.176568</td>\n",
       "      <td>1206.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.558900e+04</td>\n",
       "      <td>7.780000e+02</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>4.876542e+01</td>\n",
       "      <td>14.029113</td>\n",
       "      <td>2.299666</td>\n",
       "      <td>0.341936</td>\n",
       "      <td>3.555194</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>773.000000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>4.876542e+01</td>\n",
       "      <td>14.029113</td>\n",
       "      <td>2.251398</td>\n",
       "      <td>0.341936</td>\n",
       "      <td>3.342999</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>54.925234</td>\n",
       "      <td>2206.420734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.927380e+05</td>\n",
       "      <td>2.838000e+03</td>\n",
       "      <td>6734.000000</td>\n",
       "      <td>3.498196e+02</td>\n",
       "      <td>118.704407</td>\n",
       "      <td>7.198330</td>\n",
       "      <td>1.320681</td>\n",
       "      <td>10.691878</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>6734.000000</td>\n",
       "      <td>3.743699e+02</td>\n",
       "      <td>107.081021</td>\n",
       "      <td>6.866840</td>\n",
       "      <td>1.320681</td>\n",
       "      <td>10.600502</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>112.191489</td>\n",
       "      <td>4349.908608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.654319e+07</td>\n",
       "      <td>1.165830e+06</td>\n",
       "      <td>549144.000000</td>\n",
       "      <td>1.145219e+06</td>\n",
       "      <td>435825.874241</td>\n",
       "      <td>76.809514</td>\n",
       "      <td>16.290540</td>\n",
       "      <td>193.072418</td>\n",
       "      <td>920838.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>664324.000000</td>\n",
       "      <td>549144.000000</td>\n",
       "      <td>1.145219e+06</td>\n",
       "      <td>435825.874241</td>\n",
       "      <td>76.809514</td>\n",
       "      <td>16.290540</td>\n",
       "      <td>193.072418</td>\n",
       "      <td>920838.000000</td>\n",
       "      <td>1861.583333</td>\n",
       "      <td>75526.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Choice  A_follower_count  A_following_count  A_listed_count  \\\n",
       "count  5500.000000      5.500000e+03       5.500000e+03     5500.000000   \n",
       "mean      0.509455      6.498840e+05       1.265895e+04     5952.453273   \n",
       "std       0.499956      2.028787e+06       4.900867e+04    17339.141191   \n",
       "min       0.000000      1.600000e+01       0.000000e+00        0.000000   \n",
       "25%       0.000000      2.663750e+03       3.220000e+02       85.000000   \n",
       "50%       1.000000      4.558900e+04       7.780000e+02      932.000000   \n",
       "75%       1.000000      3.927380e+05       2.838000e+03     6734.000000   \n",
       "max       1.000000      3.654319e+07       1.165830e+06   549144.000000   \n",
       "\n",
       "       A_mentions_received  A_retweets_received  A_mentions_sent  \\\n",
       "count         5.500000e+03          5500.000000      5500.000000   \n",
       "mean          2.666032e+03          1032.371839         6.011873   \n",
       "std           2.916543e+04         10954.953223         9.519797   \n",
       "min           1.005034e-01             0.100503         0.100503   \n",
       "25%           3.453649e+00             0.716816         0.359534   \n",
       "50%           4.876542e+01            14.029113         2.299666   \n",
       "75%           3.498196e+02           118.704407         7.198330   \n",
       "max           1.145219e+06        435825.874241        76.809514   \n",
       "\n",
       "       A_retweets_sent      A_posts  A_network_feature_1  ...  \\\n",
       "count      5500.000000  5500.000000          5500.000000  ...   \n",
       "mean          1.109924     9.090730          5267.768000  ...   \n",
       "std           1.910104    18.311060         28946.777345  ...   \n",
       "min           0.100503     0.100503             0.000000  ...   \n",
       "25%           0.100503     0.632440            12.000000  ...   \n",
       "50%           0.341936     3.555194           195.000000  ...   \n",
       "75%           1.320681    10.691878          1323.000000  ...   \n",
       "max          16.290540   193.072418        920838.000000  ...   \n",
       "\n",
       "       B_following_count  B_listed_count  B_mentions_received  \\\n",
       "count        5500.000000     5500.000000         5.500000e+03   \n",
       "mean        12738.259818     5903.148364         2.554598e+03   \n",
       "std         50054.520874    16298.462018         2.508873e+04   \n",
       "min             0.000000        0.000000         1.005034e-01   \n",
       "25%           322.000000       75.000000         3.260473e+00   \n",
       "50%           773.000000      890.000000         4.876542e+01   \n",
       "75%          2838.000000     6734.000000         3.743699e+02   \n",
       "max        664324.000000   549144.000000         1.145219e+06   \n",
       "\n",
       "       B_retweets_received  B_mentions_sent  B_retweets_sent      B_posts  \\\n",
       "count          5500.000000      5500.000000      5500.000000  5500.000000   \n",
       "mean            997.149954         6.099658         1.106236     9.505821   \n",
       "std            9342.006880         9.729557         1.939914    19.424680   \n",
       "min               0.100503         0.100503         0.100503     0.100503   \n",
       "25%               0.714556         0.356943         0.100503     0.822584   \n",
       "50%              14.029113         2.251398         0.341936     3.342999   \n",
       "75%             107.081021         6.866840         1.320681    10.600502   \n",
       "max          435825.874241        76.809514        16.290540   193.072418   \n",
       "\n",
       "       B_network_feature_1  B_network_feature_2  B_network_feature_3  \n",
       "count          5500.000000          5500.000000          5500.000000  \n",
       "mean           5254.933636            85.024196          3745.175480  \n",
       "std           26778.820125           106.689384          5518.399590  \n",
       "min               0.000000             0.000000             0.000000  \n",
       "25%              11.000000            15.176568          1206.500000  \n",
       "50%             190.000000            54.925234          2206.420734  \n",
       "75%            1323.000000           112.191489          4349.908608  \n",
       "max          920838.000000          1861.583333         75526.083333  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5500 entries, 0 to 5499\n",
      "Data columns (total 23 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Choice               5500 non-null   int64  \n",
      " 1   A_follower_count     5500 non-null   int64  \n",
      " 2   A_following_count    5500 non-null   int64  \n",
      " 3   A_listed_count       5500 non-null   int64  \n",
      " 4   A_mentions_received  5500 non-null   float64\n",
      " 5   A_retweets_received  5500 non-null   float64\n",
      " 6   A_mentions_sent      5500 non-null   float64\n",
      " 7   A_retweets_sent      5500 non-null   float64\n",
      " 8   A_posts              5500 non-null   float64\n",
      " 9   A_network_feature_1  5500 non-null   int64  \n",
      " 10  A_network_feature_2  5500 non-null   float64\n",
      " 11  A_network_feature_3  5500 non-null   float64\n",
      " 12  B_follower_count     5500 non-null   int64  \n",
      " 13  B_following_count    5500 non-null   int64  \n",
      " 14  B_listed_count       5500 non-null   int64  \n",
      " 15  B_mentions_received  5500 non-null   float64\n",
      " 16  B_retweets_received  5500 non-null   float64\n",
      " 17  B_mentions_sent      5500 non-null   float64\n",
      " 18  B_retweets_sent      5500 non-null   float64\n",
      " 19  B_posts              5500 non-null   float64\n",
      " 20  B_network_feature_1  5500 non-null   int64  \n",
      " 21  B_network_feature_2  5500 non-null   float64\n",
      " 22  B_network_feature_3  5500 non-null   float64\n",
      "dtypes: float64(14), int64(9)\n",
      "memory usage: 988.4 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Choice</th>\n",
       "      <th>follower_count_sum</th>\n",
       "      <th>follower_count_diff</th>\n",
       "      <th>follower_count_ratio</th>\n",
       "      <th>follower_count_normalized_diff</th>\n",
       "      <th>following_count_sum</th>\n",
       "      <th>following_count_diff</th>\n",
       "      <th>following_count_ratio</th>\n",
       "      <th>following_count_normalized_diff</th>\n",
       "      <th>listed_count_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>network_feature_1_ratio</th>\n",
       "      <th>network_feature_1_normalized_diff</th>\n",
       "      <th>network_feature_2_sum</th>\n",
       "      <th>network_feature_2_diff</th>\n",
       "      <th>network_feature_2_ratio</th>\n",
       "      <th>network_feature_2_normalized_diff</th>\n",
       "      <th>network_feature_3_sum</th>\n",
       "      <th>network_feature_3_diff</th>\n",
       "      <th>network_feature_3_ratio</th>\n",
       "      <th>network_feature_3_normalized_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34691</td>\n",
       "      <td>-34235</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>-0.986855</td>\n",
       "      <td>30110</td>\n",
       "      <td>-29506</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>-0.979940</td>\n",
       "      <td>1692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>-0.941175</td>\n",
       "      <td>242.030303</td>\n",
       "      <td>90.969697</td>\n",
       "      <td>2.204410</td>\n",
       "      <td>0.375861</td>\n",
       "      <td>13271.893939</td>\n",
       "      <td>9438.106061</td>\n",
       "      <td>5.923645</td>\n",
       "      <td>0.711135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>60853</td>\n",
       "      <td>-17671</td>\n",
       "      <td>0.549921</td>\n",
       "      <td>-0.290388</td>\n",
       "      <td>2027</td>\n",
       "      <td>331</td>\n",
       "      <td>1.390330</td>\n",
       "      <td>0.163296</td>\n",
       "      <td>1838</td>\n",
       "      <td>...</td>\n",
       "      <td>2.263802</td>\n",
       "      <td>0.387218</td>\n",
       "      <td>150.473646</td>\n",
       "      <td>-113.587704</td>\n",
       "      <td>0.139687</td>\n",
       "      <td>-0.754867</td>\n",
       "      <td>4261.881385</td>\n",
       "      <td>-1601.149290</td>\n",
       "      <td>0.453815</td>\n",
       "      <td>-0.375691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10932</td>\n",
       "      <td>3688</td>\n",
       "      <td>2.018222</td>\n",
       "      <td>0.337358</td>\n",
       "      <td>1697</td>\n",
       "      <td>733</td>\n",
       "      <td>2.520746</td>\n",
       "      <td>0.431939</td>\n",
       "      <td>307</td>\n",
       "      <td>...</td>\n",
       "      <td>31.665611</td>\n",
       "      <td>0.938775</td>\n",
       "      <td>79.261168</td>\n",
       "      <td>58.594502</td>\n",
       "      <td>6.670371</td>\n",
       "      <td>0.739258</td>\n",
       "      <td>6277.230241</td>\n",
       "      <td>5722.563574</td>\n",
       "      <td>21.634236</td>\n",
       "      <td>0.911638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>19582</td>\n",
       "      <td>-19542</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>-0.997957</td>\n",
       "      <td>17644</td>\n",
       "      <td>-17630</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>-0.999207</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>-0.993213</td>\n",
       "      <td>25.469296</td>\n",
       "      <td>-21.469296</td>\n",
       "      <td>0.085217</td>\n",
       "      <td>-0.842945</td>\n",
       "      <td>1492.012300</td>\n",
       "      <td>-1299.678967</td>\n",
       "      <td>0.068895</td>\n",
       "      <td>-0.871091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>53143</td>\n",
       "      <td>38035</td>\n",
       "      <td>6.035081</td>\n",
       "      <td>0.715710</td>\n",
       "      <td>2573</td>\n",
       "      <td>-849</td>\n",
       "      <td>0.503799</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>2822</td>\n",
       "      <td>...</td>\n",
       "      <td>6.482345</td>\n",
       "      <td>0.732704</td>\n",
       "      <td>175.904293</td>\n",
       "      <td>78.904293</td>\n",
       "      <td>2.626887</td>\n",
       "      <td>0.448564</td>\n",
       "      <td>4827.475850</td>\n",
       "      <td>840.220036</td>\n",
       "      <td>1.421453</td>\n",
       "      <td>0.174050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Choice  follower_count_sum  follower_count_diff  follower_count_ratio  \\\n",
       "0       0               34691               -34235              0.006616   \n",
       "1       0               60853               -17671              0.549921   \n",
       "2       0               10932                 3688              2.018222   \n",
       "3       0               19582               -19542              0.001022   \n",
       "4       1               53143                38035              6.035081   \n",
       "\n",
       "   follower_count_normalized_diff  following_count_sum  following_count_diff  \\\n",
       "0                       -0.986855                30110                -29506   \n",
       "1                       -0.290388                 2027                   331   \n",
       "2                        0.337358                 1697                   733   \n",
       "3                       -0.997957                17644                -17630   \n",
       "4                        0.715710                 2573                  -849   \n",
       "\n",
       "   following_count_ratio  following_count_normalized_diff  listed_count_sum  \\\n",
       "0               0.010132                        -0.979940              1692   \n",
       "1               1.390330                         0.163296              1838   \n",
       "2               2.520746                         0.431939               307   \n",
       "3               0.000397                        -0.999207               280   \n",
       "4               0.503799                        -0.329965              2822   \n",
       "\n",
       "   ...  network_feature_1_ratio  network_feature_1_normalized_diff  \\\n",
       "0  ...                 0.030303                          -0.941175   \n",
       "1  ...                 2.263802                           0.387218   \n",
       "2  ...                31.665611                           0.938775   \n",
       "3  ...                 0.003405                          -0.993213   \n",
       "4  ...                 6.482345                           0.732704   \n",
       "\n",
       "   network_feature_2_sum  network_feature_2_diff  network_feature_2_ratio  \\\n",
       "0             242.030303               90.969697                 2.204410   \n",
       "1             150.473646             -113.587704                 0.139687   \n",
       "2              79.261168               58.594502                 6.670371   \n",
       "3              25.469296              -21.469296                 0.085217   \n",
       "4             175.904293               78.904293                 2.626887   \n",
       "\n",
       "   network_feature_2_normalized_diff  network_feature_3_sum  \\\n",
       "0                           0.375861           13271.893939   \n",
       "1                          -0.754867            4261.881385   \n",
       "2                           0.739258            6277.230241   \n",
       "3                          -0.842945            1492.012300   \n",
       "4                           0.448564            4827.475850   \n",
       "\n",
       "   network_feature_3_diff  network_feature_3_ratio  \\\n",
       "0             9438.106061                 5.923645   \n",
       "1            -1601.149290                 0.453815   \n",
       "2             5722.563574                21.634236   \n",
       "3            -1299.678967                 0.068895   \n",
       "4              840.220036                 1.421453   \n",
       "\n",
       "   network_feature_3_normalized_diff  \n",
       "0                           0.711135  \n",
       "1                          -0.375691  \n",
       "2                           0.911638  \n",
       "3                          -0.871091  \n",
       "4                           0.174050  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of features for which to perform the transformations, excluding 'Choice'\n",
    "features = [col[2:] for col in train_df.columns if col.startswith('A_')]\n",
    "\n",
    "# Initialize a new DataFrame to store transformed features\n",
    "transformed_data = train_df[['Choice']].copy()\n",
    "\n",
    "for feature in features:\n",
    "    A = train_df['A_' + feature]\n",
    "    B = train_df['B_' + feature]\n",
    "    \n",
    "    transformed_data[feature + '_sum'] = A + B\n",
    "    transformed_data[feature + '_diff'] = A - B\n",
    "    \n",
    "    # Adding a small number to avoid division by zero\n",
    "    transformed_data[feature + '_ratio'] = A / (B + 0.0001)  \n",
    "    transformed_data[feature + '_normalized_diff'] = (A - B) / (A + B + 0.0001)  \n",
    "\n",
    "transformed_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>follower_count_sum</th>\n",
       "      <th>follower_count_diff</th>\n",
       "      <th>follower_count_ratio</th>\n",
       "      <th>follower_count_normalized_diff</th>\n",
       "      <th>following_count_sum</th>\n",
       "      <th>following_count_diff</th>\n",
       "      <th>following_count_ratio</th>\n",
       "      <th>following_count_normalized_diff</th>\n",
       "      <th>listed_count_sum</th>\n",
       "      <th>listed_count_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>network_feature_1_ratio</th>\n",
       "      <th>network_feature_1_normalized_diff</th>\n",
       "      <th>network_feature_2_sum</th>\n",
       "      <th>network_feature_2_diff</th>\n",
       "      <th>network_feature_2_ratio</th>\n",
       "      <th>network_feature_2_normalized_diff</th>\n",
       "      <th>network_feature_3_sum</th>\n",
       "      <th>network_feature_3_diff</th>\n",
       "      <th>network_feature_3_ratio</th>\n",
       "      <th>network_feature_3_normalized_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.507400</td>\n",
       "      <td>1.385622e-08</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>1.790937e-11</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.510798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.417896e-11</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.126954</td>\n",
       "      <td>0.659024</td>\n",
       "      <td>2.636854e-07</td>\n",
       "      <td>0.687930</td>\n",
       "      <td>0.090481</td>\n",
       "      <td>0.386341</td>\n",
       "      <td>1.329181e-08</td>\n",
       "      <td>0.855567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.507632</td>\n",
       "      <td>1.152530e-06</td>\n",
       "      <td>0.354804</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.363888</td>\n",
       "      <td>2.457673e-09</td>\n",
       "      <td>0.581648</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.511084</td>\n",
       "      <td>...</td>\n",
       "      <td>1.059247e-09</td>\n",
       "      <td>0.693609</td>\n",
       "      <td>0.078929</td>\n",
       "      <td>0.588358</td>\n",
       "      <td>1.670896e-08</td>\n",
       "      <td>0.122566</td>\n",
       "      <td>0.029055</td>\n",
       "      <td>0.335476</td>\n",
       "      <td>1.018296e-09</td>\n",
       "      <td>0.312155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.507932</td>\n",
       "      <td>4.229835e-06</td>\n",
       "      <td>0.668679</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.364108</td>\n",
       "      <td>4.455899e-09</td>\n",
       "      <td>0.715969</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.512285</td>\n",
       "      <td>...</td>\n",
       "      <td>1.481654e-08</td>\n",
       "      <td>0.969387</td>\n",
       "      <td>0.041575</td>\n",
       "      <td>0.647840</td>\n",
       "      <td>7.978913e-07</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>0.042795</td>\n",
       "      <td>0.369221</td>\n",
       "      <td>4.854411e-08</td>\n",
       "      <td>0.955819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.507606</td>\n",
       "      <td>2.133421e-09</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>0.354055</td>\n",
       "      <td>7.015837e-13</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.512124</td>\n",
       "      <td>...</td>\n",
       "      <td>1.593324e-12</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.013360</td>\n",
       "      <td>0.620181</td>\n",
       "      <td>1.019346e-08</td>\n",
       "      <td>0.078527</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.336865</td>\n",
       "      <td>1.545902e-10</td>\n",
       "      <td>0.064454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.508414</td>\n",
       "      <td>1.264848e-05</td>\n",
       "      <td>0.857856</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.363242</td>\n",
       "      <td>8.905604e-10</td>\n",
       "      <td>0.335017</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.514698</td>\n",
       "      <td>...</td>\n",
       "      <td>3.033130e-09</td>\n",
       "      <td>0.866352</td>\n",
       "      <td>0.092268</td>\n",
       "      <td>0.654856</td>\n",
       "      <td>3.142210e-07</td>\n",
       "      <td>0.724282</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.346725</td>\n",
       "      <td>3.189535e-09</td>\n",
       "      <td>0.587025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   follower_count_sum  follower_count_diff  follower_count_ratio  \\\n",
       "0            0.000481             0.507400          1.385622e-08   \n",
       "1            0.000844             0.507632          1.152530e-06   \n",
       "2            0.000150             0.507932          4.229835e-06   \n",
       "3            0.000271             0.507606          2.133421e-09   \n",
       "4            0.000737             0.508414          1.264848e-05   \n",
       "\n",
       "   follower_count_normalized_diff  following_count_sum  following_count_diff  \\\n",
       "0                        0.006568             0.025744              0.347553   \n",
       "1                        0.354804             0.001730              0.363888   \n",
       "2                        0.668679             0.001448              0.364108   \n",
       "3                        0.001017             0.015084              0.354055   \n",
       "4                        0.857856             0.002197              0.363242   \n",
       "\n",
       "   following_count_ratio  following_count_normalized_diff  listed_count_sum  \\\n",
       "0           1.790937e-11                         0.010030          0.002135   \n",
       "1           2.457673e-09                         0.581648          0.002319   \n",
       "2           4.455899e-09                         0.715969          0.000386   \n",
       "3           7.015837e-13                         0.000397          0.000352   \n",
       "4           8.905604e-10                         0.335017          0.003561   \n",
       "\n",
       "   listed_count_diff  ...  network_feature_1_ratio  \\\n",
       "0           0.510798  ...             1.417896e-11   \n",
       "1           0.511084  ...             1.059247e-09   \n",
       "2           0.512285  ...             1.481654e-08   \n",
       "3           0.512124  ...             1.593324e-12   \n",
       "4           0.514698  ...             3.033130e-09   \n",
       "\n",
       "   network_feature_1_normalized_diff  network_feature_2_sum  \\\n",
       "0                           0.029412               0.126954   \n",
       "1                           0.693609               0.078929   \n",
       "2                           0.969387               0.041575   \n",
       "3                           0.003394               0.013360   \n",
       "4                           0.866352               0.092268   \n",
       "\n",
       "   network_feature_2_diff  network_feature_2_ratio  \\\n",
       "0                0.659024             2.636854e-07   \n",
       "1                0.588358             1.670896e-08   \n",
       "2                0.647840             7.978913e-07   \n",
       "3                0.620181             1.019346e-08   \n",
       "4                0.654856             3.142210e-07   \n",
       "\n",
       "   network_feature_2_normalized_diff  network_feature_3_sum  \\\n",
       "0                           0.687930               0.090481   \n",
       "1                           0.122566               0.029055   \n",
       "2                           0.869629               0.042795   \n",
       "3                           0.078527               0.010172   \n",
       "4                           0.724282               0.032911   \n",
       "\n",
       "   network_feature_3_diff  network_feature_3_ratio  \\\n",
       "0                0.386341             1.329181e-08   \n",
       "1                0.335476             1.018296e-09   \n",
       "2                0.369221             4.854411e-08   \n",
       "3                0.336865             1.545902e-10   \n",
       "4                0.346725             3.189535e-09   \n",
       "\n",
       "   network_feature_3_normalized_diff  \n",
       "0                           0.855567  \n",
       "1                           0.312155  \n",
       "2                           0.955819  \n",
       "3                           0.064454  \n",
       "4                           0.587025  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = transformed_data.drop('Choice', axis=1)\n",
    "y = transformed_data['Choice']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "X_normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "\n",
    "X_normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized_df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.771429 (0.022851)\n",
      "KNN: nan (nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.707273 (0.021980)\n",
      "RF: 0.769091 (0.024100)\n",
      "NB: 0.581558 (0.014483)\n",
      "SVM: 0.765714 (0.019115)\n",
      "XGB: 0.754286 (0.023868)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define models to evaluate\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('XGB', XGBClassifier(use_label_encoder=False, eval_metric='logloss')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.770303 (0.035593)\n",
      "KNN: nan (nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.726667 (0.031776)\n",
      "RF: 0.760000 (0.040854)\n",
      "NB: 0.637576 (0.015523)\n",
      "SVM: 0.773333 (0.034731)\n",
      "XGB: 0.754545 (0.044557)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_test, y_test, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>mentions_received_normalized_diff</td>\n",
       "      <td>network_feature_1_normalized_diff</td>\n",
       "      <td>0.995093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>mentions_received_sum</td>\n",
       "      <td>retweets_received_sum</td>\n",
       "      <td>0.988603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>mentions_received_diff</td>\n",
       "      <td>retweets_received_diff</td>\n",
       "      <td>0.988363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>mentions_received_normalized_diff</td>\n",
       "      <td>retweets_received_normalized_diff</td>\n",
       "      <td>0.948903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>retweets_received_normalized_diff</td>\n",
       "      <td>network_feature_1_normalized_diff</td>\n",
       "      <td>0.948086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>retweets_received_sum</td>\n",
       "      <td>network_feature_1_sum</td>\n",
       "      <td>0.923584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>retweets_received_diff</td>\n",
       "      <td>network_feature_1_diff</td>\n",
       "      <td>0.920574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>mentions_received_sum</td>\n",
       "      <td>network_feature_1_sum</td>\n",
       "      <td>0.916290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>mentions_received_diff</td>\n",
       "      <td>network_feature_1_diff</td>\n",
       "      <td>0.914479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>follower_count_normalized_diff</td>\n",
       "      <td>listed_count_normalized_diff</td>\n",
       "      <td>0.895252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>mentions_received_ratio</td>\n",
       "      <td>network_feature_1_ratio</td>\n",
       "      <td>0.891700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>network_feature_2_normalized_diff</td>\n",
       "      <td>network_feature_3_normalized_diff</td>\n",
       "      <td>0.860176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>follower_count_sum</td>\n",
       "      <td>listed_count_sum</td>\n",
       "      <td>0.845822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>mentions_sent_normalized_diff</td>\n",
       "      <td>posts_normalized_diff</td>\n",
       "      <td>0.829701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>follower_count_normalized_diff</td>\n",
       "      <td>network_feature_1_normalized_diff</td>\n",
       "      <td>0.817307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>listed_count_normalized_diff</td>\n",
       "      <td>network_feature_1_normalized_diff</td>\n",
       "      <td>0.817115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>follower_count_normalized_diff</td>\n",
       "      <td>mentions_received_normalized_diff</td>\n",
       "      <td>0.807321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>listed_count_normalized_diff</td>\n",
       "      <td>mentions_received_normalized_diff</td>\n",
       "      <td>0.805538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Feature1                           Feature2  \\\n",
       "695   mentions_received_normalized_diff  network_feature_1_normalized_diff   \n",
       "544               mentions_received_sum              retweets_received_sum   \n",
       "589              mentions_received_diff             retweets_received_diff   \n",
       "679   mentions_received_normalized_diff  retweets_received_normalized_diff   \n",
       "871   retweets_received_normalized_diff  network_feature_1_normalized_diff   \n",
       "736               retweets_received_sum              network_feature_1_sum   \n",
       "781              retweets_received_diff             network_feature_1_diff   \n",
       "560               mentions_received_sum              network_feature_1_sum   \n",
       "605              mentions_received_diff             network_feature_1_diff   \n",
       "143      follower_count_normalized_diff       listed_count_normalized_diff   \n",
       "650             mentions_received_ratio            network_feature_1_ratio   \n",
       "1759  network_feature_2_normalized_diff  network_feature_3_normalized_diff   \n",
       "8                    follower_count_sum                   listed_count_sum   \n",
       "1043      mentions_sent_normalized_diff              posts_normalized_diff   \n",
       "167      follower_count_normalized_diff  network_feature_1_normalized_diff   \n",
       "519        listed_count_normalized_diff  network_feature_1_normalized_diff   \n",
       "147      follower_count_normalized_diff  mentions_received_normalized_diff   \n",
       "499        listed_count_normalized_diff  mentions_received_normalized_diff   \n",
       "\n",
       "      Correlation  \n",
       "695      0.995093  \n",
       "544      0.988603  \n",
       "589      0.988363  \n",
       "679      0.948903  \n",
       "871      0.948086  \n",
       "736      0.923584  \n",
       "781      0.920574  \n",
       "560      0.916290  \n",
       "605      0.914479  \n",
       "143      0.895252  \n",
       "650      0.891700  \n",
       "1759     0.860176  \n",
       "8        0.845822  \n",
       "1043     0.829701  \n",
       "167      0.817307  \n",
       "519      0.817115  \n",
       "147      0.807321  \n",
       "499      0.805538  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = X_normalized_df.corr()\n",
    "\n",
    "high_corr_pairs = correlation_matrix.abs().stack().reset_index()\n",
    "high_corr_pairs.columns = ['Feature1', 'Feature2', 'Correlation']\n",
    "high_corr_pairs = high_corr_pairs[high_corr_pairs['Feature1'] != high_corr_pairs['Feature2']]  # Remove self-correlation\n",
    "high_corr_pairs = high_corr_pairs[high_corr_pairs['Correlation'] > 0.8]\n",
    "high_corr_pairs = high_corr_pairs.drop_duplicates(subset=['Correlation'])\n",
    "high_corr_pairs = high_corr_pairs.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# Display high correlation pairs\n",
    "high_corr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features to remove\n",
    "features_to_remove = [\n",
    "    'network_feature_1_normalized_diff',\n",
    "    'retweets_received_sum',\n",
    "    'retweets_received_diff',\n",
    "    'listed_count_sum',\n",
    "    'posts_normalized_diff',\n",
    "    'network_feature_3_normalized_diff'\n",
    "]\n",
    "\n",
    "# Remove the selected features\n",
    "X_normalized_df = X_normalized_df.drop(features_to_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>listed_count_normalized_diff</td>\n",
       "      <td>0.104355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>listed_count_diff</td>\n",
       "      <td>0.073460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>follower_count_normalized_diff</td>\n",
       "      <td>0.060548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>retweets_received_normalized_diff</td>\n",
       "      <td>0.058342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mentions_received_normalized_diff</td>\n",
       "      <td>0.056207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>follower_count_diff</td>\n",
       "      <td>0.054794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>network_feature_1_diff</td>\n",
       "      <td>0.047538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>follower_count_ratio</td>\n",
       "      <td>0.033873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>retweets_received_ratio</td>\n",
       "      <td>0.031230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mentions_received_diff</td>\n",
       "      <td>0.030345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>network_feature_2_diff</td>\n",
       "      <td>0.023673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>network_feature_2_normalized_diff</td>\n",
       "      <td>0.023451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>network_feature_2_sum</td>\n",
       "      <td>0.022001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>following_count_diff</td>\n",
       "      <td>0.021891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>posts_ratio</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>following_count_sum</td>\n",
       "      <td>0.021177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>network_feature_3_diff</td>\n",
       "      <td>0.021175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>follower_count_sum</td>\n",
       "      <td>0.020627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>following_count_normalized_diff</td>\n",
       "      <td>0.020192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>posts_sum</td>\n",
       "      <td>0.020066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mentions_sent_diff</td>\n",
       "      <td>0.020025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mentions_sent_ratio</td>\n",
       "      <td>0.019999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>posts_diff</td>\n",
       "      <td>0.019986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>network_feature_3_sum</td>\n",
       "      <td>0.019978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mentions_sent_normalized_diff</td>\n",
       "      <td>0.019445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mentions_sent_sum</td>\n",
       "      <td>0.017992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mentions_received_sum</td>\n",
       "      <td>0.017540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>retweets_sent_normalized_diff</td>\n",
       "      <td>0.016979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>network_feature_1_sum</td>\n",
       "      <td>0.016672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>retweets_sent_diff</td>\n",
       "      <td>0.014812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>retweets_sent_ratio</td>\n",
       "      <td>0.014651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>retweets_sent_sum</td>\n",
       "      <td>0.013971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mentions_received_ratio</td>\n",
       "      <td>0.011116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>network_feature_2_ratio</td>\n",
       "      <td>0.005534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>following_count_ratio</td>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>network_feature_3_ratio</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>listed_count_ratio</td>\n",
       "      <td>0.000789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>network_feature_1_ratio</td>\n",
       "      <td>0.000771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Feature  Importance\n",
       "10       listed_count_normalized_diff    0.104355\n",
       "8                   listed_count_diff    0.073460\n",
       "3      follower_count_normalized_diff    0.060548\n",
       "16  retweets_received_normalized_diff    0.058342\n",
       "14  mentions_received_normalized_diff    0.056207\n",
       "1                 follower_count_diff    0.054794\n",
       "29             network_feature_1_diff    0.047538\n",
       "2                follower_count_ratio    0.033873\n",
       "15            retweets_received_ratio    0.031230\n",
       "12             mentions_received_diff    0.030345\n",
       "32             network_feature_2_diff    0.023673\n",
       "34  network_feature_2_normalized_diff    0.023451\n",
       "31              network_feature_2_sum    0.022001\n",
       "5                following_count_diff    0.021891\n",
       "27                        posts_ratio    0.021500\n",
       "4                 following_count_sum    0.021177\n",
       "36             network_feature_3_diff    0.021175\n",
       "0                  follower_count_sum    0.020627\n",
       "7     following_count_normalized_diff    0.020192\n",
       "25                          posts_sum    0.020066\n",
       "18                 mentions_sent_diff    0.020025\n",
       "19                mentions_sent_ratio    0.019999\n",
       "26                         posts_diff    0.019986\n",
       "35              network_feature_3_sum    0.019978\n",
       "20      mentions_sent_normalized_diff    0.019445\n",
       "17                  mentions_sent_sum    0.017992\n",
       "11              mentions_received_sum    0.017540\n",
       "24      retweets_sent_normalized_diff    0.016979\n",
       "28              network_feature_1_sum    0.016672\n",
       "22                 retweets_sent_diff    0.014812\n",
       "23                retweets_sent_ratio    0.014651\n",
       "21                  retweets_sent_sum    0.013971\n",
       "13            mentions_received_ratio    0.011116\n",
       "33            network_feature_2_ratio    0.005534\n",
       "6               following_count_ratio    0.002189\n",
       "37            network_feature_3_ratio    0.001108\n",
       "9                  listed_count_ratio    0.000789\n",
       "30            network_feature_1_ratio    0.000771"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_normalized_df, y)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature names and their importance scores\n",
    "feature_importances_df = pd.DataFrame({'Feature': X_normalized_df.columns, 'Importance': feature_importances})\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(feature_importances_df,'feature_importances_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 26 features\n",
    "top_features = feature_importances_df['Feature'].head(20)\n",
    "\n",
    "# Filter the dataset to include only the top 26 features\n",
    "X_filtered = X_normalized_df[top_features]\n",
    "\n",
    "# Split the filtered dataset into training and testing sets\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(X_filtered, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factors are best predictors of influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10         listed_count_normalized_diff\n",
       "8                     listed_count_diff\n",
       "3        follower_count_normalized_diff\n",
       "16    retweets_received_normalized_diff\n",
       "14    mentions_received_normalized_diff\n",
       "1                   follower_count_diff\n",
       "29               network_feature_1_diff\n",
       "2                  follower_count_ratio\n",
       "15              retweets_received_ratio\n",
       "12               mentions_received_diff\n",
       "32               network_feature_2_diff\n",
       "34    network_feature_2_normalized_diff\n",
       "31                network_feature_2_sum\n",
       "5                  following_count_diff\n",
       "27                          posts_ratio\n",
       "4                   following_count_sum\n",
       "36               network_feature_3_diff\n",
       "0                    follower_count_sum\n",
       "7       following_count_normalized_diff\n",
       "25                            posts_sum\n",
       "Name: Feature, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.765195 (0.022168)\n",
      "KNN: nan (nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.696364 (0.020923)\n",
      "RF: 0.772468 (0.021488)\n",
      "NB: 0.742338 (0.014499)\n",
      "SVM: 0.762338 (0.020094)\n",
      "XGB: 0.752208 (0.026005)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('XGB', XGBClassifier(use_label_encoder=False, eval_metric='logloss')))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train_filtered, y_train_filtered, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.768485 (0.035629)\n",
      "KNN: nan (nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/addisonji/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.733939 (0.033465)\n",
      "RF: 0.769091 (0.032575)\n",
      "NB: 0.683030 (0.023480)\n",
      "SVM: 0.767273 (0.037673)\n",
      "XGB: 0.749697 (0.030790)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model in turn\n",
    "results_filtered = []\n",
    "names_filtered = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results_filtered = cross_val_score(model, X_test_filtered, y_test_filtered, cv=kfold, scoring='accuracy')\n",
    "    results_filtered.append(cv_results)\n",
    "    names_filtered.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results_filtered.mean(), cv_results_filtered.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_scores = [np.mean(r) for r in results]  # Up to SVM, excluding XGB\n",
    "mean_scores_filtered = [np.mean(r) for r in results_filtered]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(mean_scores))\n",
    "\n",
    "bars1 = ax.bar(index, mean_scores, bar_width, label='All Features')\n",
    "bars2 = ax.bar(index + bar_width, mean_scores_filtered, bar_width, label='Selected Features')\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Model Accuracy Before and After Feature Selection')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(names, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best Parameters: {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Accuracy: 0.7794805194805194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [5,100,500],\n",
    "    'max_depth': [None, 2, 5, 7, 9, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_filtered, y_train_filtered)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       820\n",
      "           1       0.76      0.81      0.79       830\n",
      "\n",
      "    accuracy                           0.78      1650\n",
      "   macro avg       0.78      0.78      0.78      1650\n",
      "weighted avg       0.78      0.78      0.78      1650\n",
      "\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   4.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=2, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END max_depth=5, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=7, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=7, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   2.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=9, min_samples_leaf=1, min_samples_split=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.2s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=9, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=500; total time=   3.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict using the best estimator found by GridSearchCV\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_filtered,)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "mat = confusion_matrix(y_test_filtered, y_pred)\n",
    "\n",
    "# Plot using Seaborn\n",
    "sns.heatmap(mat, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_filtered, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Saving the Random Forest model\n",
    "model_to_save = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=9, min_samples_leaf=2, min_samples_split=10)\n",
    "model_to_save.fit(X_train_filtered, y_train_filtered)  \n",
    "save_model(model_to_save, \"random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Calculate the financial value of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plug in the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "profit_per_unit = 10\n",
    "cost_per_tweet = 5\n",
    "probability_buy_influencer_once = 0.0002\n",
    "probability_buy_influencer_twice = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of People on the list\n",
    "total_people=len(train_df[\"Choice\"])*2\n",
    "total_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Influencers\n",
    "total_influencers=len(train_df[\"Choice\"])\n",
    "total_influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5376568593, 1967970867)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of flollowers for influencer and non-influencers\n",
    "data=train_df\n",
    "total_followers_influencers = data.loc[data['Choice'] == 1, 'A_follower_count'].sum() + data.loc[data['Choice'] == 0, 'B_follower_count'].sum()\n",
    "total_followers_non_influencers = data.loc[data['Choice'] == 1, 'B_follower_count'].sum() + data.loc[data['Choice'] == 0, 'A_follower_count'].sum()\n",
    "total_followers_influencers, total_followers_non_influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977557.926"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_followers_influencers/5500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Without Using Any Analytics\n",
    "#### Assuming without analytics the retailer will not know any information of who is the influencer, so the retailer will give everyone on the list five dollars to ask them tweet once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected profit without analytics is 10698137.186\n"
     ]
    }
   ],
   "source": [
    "# Financial calculations\n",
    "# Cost if everyone tweet once\n",
    "cost_without_analytics = total_people * cost_per_tweet\n",
    "# Expected sales if everyone tweet once\n",
    "expected_sales_without_analytics = total_followers_influencers * probability_buy_influencer_once * 1\n",
    "# Expected Profit\n",
    "expected_profit_without_analytics = (expected_sales_without_analytics * profit_per_unit) - cost_without_analytics\n",
    "\n",
    "print(f'The expected profit without analytics is {expected_profit_without_analytics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Using our model\n",
    "#### For this one, we will use the classification report from the training set to estimate the confusion matrix of the entire 11000 people if we run the model and trying to indentify the influencers and then the true positive and false positive would be the influencers identified from the models in the real practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters got from the classification report\n",
    "precision_0 = 0.80\n",
    "recall_0 = 0.74\n",
    "precision_1 = 0.76\n",
    "recall_1 = 0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating True Positives (TP), False Positives (FP), False Negatives (FN), True Negatives (TN)\n",
    "# For influencers (class 1)\n",
    "TP_1 = recall_1 * total_influencers  \n",
    "FN_1 = total_influencers - TP_1\n",
    "\n",
    "# For non-influencers (class 0)\n",
    "TN_0 = recall_0 * (total_people-total_influencers)\n",
    "FP_0 = (total_people-total_influencers) - TN_0  \n",
    "\n",
    "# Adjusting FP for class 1 and TN for class 0 based on the above, given that FP (class 1) = FN (class 0)\n",
    "FP_1 = FP_0\n",
    "TN_1 = TN_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected profit with our model is 13006211.68099\n"
     ]
    }
   ],
   "source": [
    "# Financial calculations\n",
    "# Paying for two tweets for TP and FP and tweet twice per person\n",
    "total_cost_model = (TP_1 + FP_1) * cost_per_tweet*2\n",
    "# Expected sales if influencers identified by the model tweet twice per person, adjust by the recall rate\n",
    "expected_sales_model = recall_1 * probability_buy_influencer_twice*total_followers_influencers*1\n",
    "# Expected Profit\n",
    "expected_profit_model = (expected_sales_model * profit_per_unit) - total_cost_model\n",
    "\n",
    "print(f'The expected profit with our model is {expected_profit_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Using perfect analytics\n",
    "#### In this scenario, assume retailer know exactly who is the influencer and will only pay them to tweet twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected profit with perfect analytic is 16074705.779\n"
     ]
    }
   ],
   "source": [
    "# Financial calculations\n",
    "# Paying for only influencers and tweet twice per person\n",
    "total_cost_perfect = total_influencers * cost_per_tweet * 2\n",
    "# Expected sales if all influencers tweet twice per person\n",
    "expected_sales_perfect = probability_buy_influencer_twice * total_followers_influencers * 1\n",
    "# Expected Profit\n",
    "expected_profit_perfect = (expected_sales_perfect * profit_per_unit) - total_cost_perfect\n",
    "\n",
    "print(f'The expected profit with perfect analytic is {expected_profit_perfect}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
